{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029d6e72-2f83-4a69-bdc5-29076e41cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Segmentation Models: using `keras` framework.\n",
      "<module 'open3d' from 'C:\\\\Users\\\\WSADMIN\\\\anaconda3\\\\lib\\\\site-packages\\\\open3d\\\\__init__.py'>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import ifm3dpy\n",
    "from ifm3dpy import * \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import keyboard\n",
    "import segmentation_models as sm\n",
    "import asyncio\n",
    "from PIL import Image\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "print(o3d)\n",
    "print(o3d.core.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1124e819-1a1c-469a-848b-2286f41cd4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import segmentation_models as sm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "class HandlingUnitExtractor():\n",
    "    def __init__(self):\n",
    "        model_file = 'best_model_handling_unit.h5'\n",
    "        self.model_img_size = (512, 512)\n",
    "        self.model = sm.Unet('efficientnetb3', classes=1, activation='sigmoid')\n",
    "        self.model.load_weights(model_file) \n",
    "        self.preprocessor = sm.get_preprocessing('efficientnetb3')\n",
    "        \n",
    "    def extract(self, img):\n",
    "        h, w = img.shape[:2]\n",
    "        image = cv2.resize(img, self.model_img_size, interpolation = cv2.INTER_AREA)\n",
    "        image = self.preprocessor(image)\n",
    "        \n",
    "        #t = time.time()\n",
    "        #mask = self.model.predict(np.expand_dims(image, axis=0)).round().squeeze()\n",
    "        mask = self.model(np.expand_dims(image, axis=0)).numpy()\n",
    "        #print(mask)\n",
    "        mask = mask.round().squeeze()\n",
    "        #print(time.time() -t)\n",
    "        mask = cv2.resize(mask, (w, h), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        mask = self.isolate_largest_component(mask)\n",
    "        \n",
    "        return mask.astype(np.uint8)\n",
    "\n",
    "    def isolate_largest_component(self, img):\n",
    "        result = np.zeros((img.shape))\n",
    "        labels, stats = cv2.connectedComponentsWithStats(img.astype(np.uint8), connectivity=8)[1:3]                   \n",
    "        \n",
    "        largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "        result[labels == largest_label] = 255 \n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51736d1c-c343-4ee6-86f4-122c77cf6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turnoffO3R(o3r):\n",
    "    config = o3r.get()\n",
    "    config['ports']['port0']['state'] = 'IDLE'\n",
    "    config['ports']['port2']['state'] = 'IDLE'\n",
    "    o3r.set(config)\n",
    "    \n",
    "def turnonO3R(o3r):\n",
    "    config = o3r.get()\n",
    "    config['ports']['port0']['state'] = 'RUN'\n",
    "    config['ports']['port2']['state'] = 'RUN'\n",
    "    o3r.set(config)\n",
    "\n",
    "# def RectificationalizationColor(image, intrinsics):    \n",
    "\n",
    "#     fx, fy, mx, my, alpha, k1, k2, k5, k3, k4, *_ = intrinsics\n",
    "\n",
    "#     dmap = image\n",
    "    \n",
    "#     KKNoAlpha = np.array([[fx, 0.0, mx],\n",
    "#                           [0,  fy,  my],\n",
    "#                           [0,  0,   1]])\n",
    "\n",
    "#     # Generate the pixel coordinates\n",
    "#     px,py = np.meshgrid(np.arange(0, dmap.shape[1]),\n",
    "#                         np.arange(0, dmap.shape[0]))\n",
    "\n",
    "#     # Homogeneous coordinates\n",
    "#     coords = np.hstack([px.reshape(-1,1) + 0.5, py.reshape(-1,1) + 0.5, np.ones([px.size, 1])]).T\n",
    "\n",
    "#     # Transfer into a normalized coordinate frame\n",
    "#     # (f=1, origin is the center, Dim: -1..1)\n",
    "#     coords_norm = np.linalg.solve(KKNoAlpha, coords)\n",
    "    \n",
    "#     # Apply distortion\n",
    "#     R2 = np.square(coords_norm[0]) + np.square(coords_norm[1])\n",
    "#     R4 = np.square(R2)\n",
    "#     R6 = np.power(R2,3)\n",
    "#     radial_dist = 1 + k1*R2 + k2*R4 + k5*R6\n",
    "\n",
    "#     a1 = 2*coords_norm[0]*coords_norm[1]\n",
    "#     a2 = R2 + 2*np.square(coords_norm[0])\n",
    "#     a3 = R2 + 2*np.square(coords_norm[1])\n",
    "#     tangential_dist = np.vstack([k3*a1 + k4*a2, k3*a3 + k4*a1])\n",
    "\n",
    "#     coord_dist = np.vstack([np.ones([2,1])*radial_dist*coords_norm[0:2] + tangential_dist, np.ones([1,px.size])])\n",
    "\n",
    "#     # Transformer --> Pixel\n",
    "#     KK = KKNoAlpha\n",
    "#     KK[0,1] = fx*alpha\n",
    "#     #KK[0,1] = alpha\n",
    "#     coord_dist = KK.dot(coord_dist)\n",
    "    \n",
    "    \n",
    "#     fr = RectBivariateSpline(np.arange(0, dmap.shape[0]),\n",
    "#                         np.arange(0, dmap.shape[1]),\n",
    "#                         dmap[:,:,0])\n",
    "#     fg = RectBivariateSpline(np.arange(0, dmap.shape[0]),\n",
    "#                         np.arange(0, dmap.shape[1]),\n",
    "#                         dmap[:,:,1])\n",
    "#     fb = RectBivariateSpline(np.arange(0, dmap.shape[0]),\n",
    "#                         np.arange(0, dmap.shape[1]),\n",
    "#                         dmap[:,:,2])\n",
    "\n",
    "#     rectifiedr = fr(coord_dist[1]-0.5, coord_dist[0]-0.5, grid=False) /255\n",
    "#     rectifiedg = fg(coord_dist[1]-0.5, coord_dist[0]-0.5, grid=False) /255\n",
    "#     rectifiedb =  fb(coord_dist[1]-0.5, coord_dist[0]-0.5, grid=False)/255\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     amp_rectifiedr = rectifiedr.reshape(dmap.shape[:2])\n",
    "#     amp_rectifiedg = rectifiedg.reshape(dmap.shape[:2])\n",
    "#     amp_rectifiedb = rectifiedb.reshape(dmap.shape[:2])\n",
    "\n",
    "    \n",
    "#     img = np.stack([amp_rectifiedr,amp_rectifiedg,amp_rectifiedb], axis=2)\n",
    "#     #img = img*255\n",
    "#     #print(img)\n",
    "#     #print(img.shape)\n",
    "#     #plt.imshow(img)\n",
    "#     return img\n",
    "    \n",
    "# def Rectificationalization(image, intrinsics):\n",
    "    \n",
    "#     amp = image\n",
    "#     # Unpack intrinsics values\n",
    "#     fx, fy, mx, my, alpha, k1, k2, k5, k3, k4, *_ = intrinsics\n",
    "\n",
    "#     # Create the camera matrix\n",
    "#     # If the current application is using the 23k imager, fx/fy/mx/my must be divided by two.\n",
    "#     # If the current application is using the full resolution imager, fx/fy/mx/my can be used 'as-is'\n",
    "    \n",
    "    \n",
    "#     KKNoAlpha = np.array([[fx, 0.0, mx],\n",
    "#                               [0,  fy,  my],\n",
    "#                               [0,  0,   1]])\n",
    "\n",
    "#     # Generate the pixel coordinates\n",
    "#     px,py = np.meshgrid(np.arange(0, amp.shape[1]),\n",
    "#                         np.arange(0, amp.shape[0]))\n",
    "\n",
    "#     # Homogeneous coordinates\n",
    "#     coords = np.hstack([px.reshape(-1,1) + 0.5, py.reshape(-1,1) + 0.5, np.ones([px.size, 1])]).T\n",
    "\n",
    "#     # Transfer into a normalized coordinate frame\n",
    "#     # (f=1, origin is the center, Dim: -1..1)\n",
    "#     coords_norm = np.linalg.solve(KKNoAlpha, coords)\n",
    "    \n",
    "#     # Apply distortion\n",
    "#     R2 = np.square(coords_norm[0]) + np.square(coords_norm[1])\n",
    "#     R4 = np.square(R2)\n",
    "#     R6 = np.power(R2,3)\n",
    "#     radial_dist = 1 + k1*R2 + k2*R4 + k5*R6\n",
    "\n",
    "#     a1 = 2*coords_norm[0]*coords_norm[1]\n",
    "#     a2 = R2 + 2*np.square(coords_norm[0])\n",
    "#     a3 = R2 + 2*np.square(coords_norm[1])\n",
    "#     tangential_dist = np.vstack([k3*a1 + k4*a2, k3*a3 + k4*a1])\n",
    "\n",
    "#     coord_dist = np.vstack([np.ones([2,1])*radial_dist*coords_norm[0:2] + tangential_dist,\n",
    "#                        np.ones([1,px.size])])\n",
    "\n",
    "#     # Transformer --> Pixel\n",
    "#     KK = KKNoAlpha\n",
    "#     KK[0,1] = fx*alpha\n",
    "#     #KK[0,1] = alpha\n",
    "#     coord_dist = KK.dot(coord_dist)\n",
    "    \n",
    "#     f = RectBivariateSpline(np.arange(0, amp.shape[0]),\n",
    "#                         np.arange(0, amp.shape[1]),\n",
    "#                         amp)\n",
    "#     rectified = f(coord_dist[1]-0.5, coord_dist[0]-0.5, grid=False)\n",
    "#     amp_rectified = rectified.reshape(amp.shape)\n",
    "#     return amp_rectified\n",
    "\n",
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')) + f' {image.shape} {image.shape[1] / image.shape[0]:.2f}'.title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    #print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    #pcd_down = pcd.to_legacy()\n",
    "    radius_normal = voxel_size * 2\n",
    "    #print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    #print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def execute_fast_global_registration(source_down, target_down, source_fpfh,\n",
    "                                     target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    #print(\":: Apply fast global registration with distance threshold %.3f\" \\ % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        o3d.pipelines.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    #print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    #print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    #print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result\n",
    "\n",
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    #distance_threshold = voxel_size * 0.4\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    #print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    #print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    #print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_ransac.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "    return result\n",
    "\n",
    "def refine_registrationP2P(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    #print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    #print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    #print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_ransac.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "    return result\n",
    "\n",
    "\n",
    "def undistort(img, config):\n",
    "    \n",
    "    mtx, newcameramtx, roi, dist = config\n",
    "    dst = cv2.undistort(img, mtx, dist, newcameramtx)\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    return dst\n",
    "\n",
    "def loadpickle(filename = 'bag'):\n",
    "    with open(filename, \"rb\") as fp:\n",
    "            frames = pickle.load(fp)\n",
    "    return frames\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "# rgb = cv2.imdecode(frames[0][1], cv2.IMREAD_UNCHANGED) \n",
    "# rgb = undistort(rgb)\n",
    "# rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)  \n",
    "# rgb = rgb[:, 95:-95]\n",
    "# rgb = cv2.resize(rgb, (224,172), interpolation = cv2.INTER_AREA)\n",
    "# plt.imshow(rgb)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def load_point_clouds(frames = None, numframes=200, picklefile= 'bag2', config=loadpickle('rgb_camera_config')): \n",
    "    pcds = []\n",
    "    maskpcds = []\n",
    "    hue = HandlingUnitExtractor()\n",
    "    for frame in frames:    \n",
    "        rgb = frame[1]\n",
    "        xyz = frame[0]  \n",
    "        \n",
    "        rgb = cv2.imdecode(rgb, cv2.IMREAD_UNCHANGED)\n",
    "        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        rgb = undistort(rgb, config)\n",
    "        \n",
    "        padup = np.zeros((100,rgb.shape[1],3))\n",
    "        paddown = np.zeros((100,rgb.shape[1],3)) \n",
    "        rgb = np.concatenate([padup, rgb, paddown], axis=0)\n",
    "        \n",
    "        #    pic = pic[:, 119:-119]\n",
    "        # pic = cv2.resize(pic, (224,172), interpolation = cv2.INTER_AREA)\n",
    "        # print(pic.shape)\n",
    "        # pic = pic/255\n",
    "        \n",
    "#         rgb = cv2.imdecode(rgb, cv2.IMREAD_UNCHANGED)\n",
    "#         rgb = undistort(rgb)         \n",
    "#         rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)  \n",
    "#         rgb = rgb[:, 95:-95]\n",
    "        \n",
    "        #mask = hue.extract(rgb)\n",
    "        \n",
    "        #rgb = rgb[1:-1, 70:-70]\n",
    "        up = 110\n",
    "        down = -126\n",
    "        left = 144\n",
    "        right = -166\n",
    "        rgb = rgb[up : down, left : right] \n",
    "        #rgb = rgb[110:-126, 119:-119]\n",
    "        \n",
    "        rgb = cv2.resize(rgb, (224,172), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        #mask = mask[:, 119:-119]        \n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB) \n",
    "        #mask[:,:,1] = 0   \n",
    "        #mask = cv2.resize(mask, (224,172), interpolation = cv2.INTER_AREA)\n",
    "       \n",
    "        #rgb = undistort(rgb)\n",
    "        \n",
    "        rgb = rgb.reshape((rgb.shape[0] * rgb.shape[1], 3))\n",
    "        rgb = rgb/255\n",
    "        \n",
    "        #mask = mask.reshape((mask.shape[0] * mask.shape[1], 3))\n",
    "        #mask = mask/255\n",
    "        \n",
    "        xyz = xyz.reshape((xyz.shape[0] * xyz.shape[1], 3))     \n",
    "        \n",
    "        \n",
    "        pcl = o3d.geometry.PointCloud()        \n",
    "        pcl.points = o3d.utility.Vector3dVector(xyz)    \n",
    "        pcl.colors = o3d.utility.Vector3dVector(rgb)         \n",
    "        pcds.append(pcl)    \n",
    "        \n",
    "        # maskpcl = o3d.geometry.PointCloud()        \n",
    "        # maskpcl.points = o3d.utility.Vector3dVector(xyz)    \n",
    "        # maskpcl.colors = o3d.utility.Vector3dVector(mask)         \n",
    "        # maskpcds.append(maskpcl)    \n",
    "        \n",
    "    \n",
    "    return  pcds, maskpcds\n",
    "\n",
    "def pairwise_registration(source, target):    \n",
    "    voxel_sizes = o3d.utility.DoubleVector([0.1, 0.05, 0.025])\n",
    "\n",
    "    # List of Convergence-Criteria for Multi-Scale ICP:\n",
    "    criteria_list = [\n",
    "        o3d.t.pipelines.registration.ICPConvergenceCriteria(relative_fitness=0.0001, relative_rmse=0.0001, max_iteration=20),\n",
    "        o3d.t.pipelines.registration.ICPConvergenceCriteria(0.00001, 0.00001, 15),\n",
    "        o3d.t.pipelines.registration.ICPConvergenceCriteria(0.000001, 0.000001, 10)\n",
    "    ]\n",
    "\n",
    "    # `max_correspondence_distances` for Multi-Scale ICP (o3d.utility.DoubleVector):\n",
    "    max_correspondence_distances = o3d.utility.DoubleVector([0.3, 0.14, 0.07])\n",
    "\n",
    "    # Initial alignment or source to target transform.\n",
    "    init_source_to_target = o3d.core.Tensor.eye(4, o3d.core.Dtype.Float32)\n",
    "\n",
    "    mu, sigma = 0, .1  # mean and standard deviation\n",
    "    # Select the `Estimation Method`, and `Robust Kernel` (for outlier-rejection).\n",
    "    #estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    #estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPlane(o3d.t.pipelines.registration.robust_kernel.RobustKernel(\n",
    "    #        o3d.t.pipelines.registration.robust_kernel.RobustKernelMethod.TukeyLoss, sigma))\n",
    "    #estimation = o3d.t.pipelines.registration.TransformationEstimationForGeneralizedICP()\n",
    "    \n",
    "    estimation = o3d.t.pipelines.registration.TransformationEstimationForColoredICP()#o3d.t.pipelines.registration.robust_kernel.RobustKernel(\n",
    "    #        o3d.t.pipelines.registration.robust_kernel.RobustKernelMethod.TukeyLoss, sigma))\n",
    "\n",
    "    #Save iteration wise `fitness`, `inlier_rmse`, etc. to analyse and tune result.\n",
    "    save_loss_log = True\n",
    "    \n",
    "    s = time.time()\n",
    "    \n",
    "\n",
    "    registration_ms_icp = o3d.t.pipelines.registration.multi_scale_icp(source, target,\n",
    "                                           voxel_sizes, criteria_list,\n",
    "                                           max_correspondence_distances, estimation_method = estimation)\n",
    "    \n",
    "    transformation_icp = registration_ms_icp.transformation\n",
    "    information_icp = o3d.t.pipelines.registration.get_information_matrix(source, target, max_correspondence_distances[2], registration_ms_icp.transformation)\n",
    "    \n",
    "    ms_icp_time = time.time() - s\n",
    "    #print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "    #print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "    #print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "    \n",
    "    return transformation_icp, information_icp\n",
    "\n",
    "\n",
    "def full_registration(pcds):\n",
    "    pose_graph = o3d.pipelines.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "\n",
    "    \n",
    "    for source_id in range(n_pcds):\n",
    "        for target_id in range(source_id + 1, n_pcds):\n",
    "            transformation_icp, information_icp = pairwise_registration(pcds[source_id], pcds[target_id])\n",
    "            \n",
    "            if target_id == source_id + 1:  # odometry case\n",
    "                odometry = np.dot(transformation_icp.numpy(), odometry)\n",
    "                pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(np.linalg.inv(odometry)))\n",
    "                pose_graph.edges.append(o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp.numpy(),\n",
    "                                                             information_icp.numpy(),\n",
    "                                                             uncertain=False))\n",
    "            else:  # loop closure case\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp.numpy(),\n",
    "                                                             information_icp.numpy(),\n",
    "                                                             uncertain=True))\n",
    "    return pose_graph\n",
    "\n",
    "\n",
    "\n",
    "def plot_rmse(registration_result):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n",
    "    axes.set_title(\"Inlier RMSE vs Iteration\")\n",
    "    axes.plot(registration_result.loss_log[\"index\"].numpy(),\n",
    "              registration_result.loss_log[\"inlier_rmse\"].numpy())\n",
    "    \n",
    "def plot_fitness(registration_result):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n",
    "    axes.set_title(\"Inlier RMSE vs Iteration\")\n",
    "    axes.plot(registration_result.loss_log[\"index\"].numpy(),\n",
    "              registration_result.loss_log[\"fitness\"].numpy())\n",
    "\n",
    "\n",
    "def plot_scale_wise_rmse(registration_result):\n",
    "    scales = registration_result.loss_log[\"scale\"].numpy()\n",
    "    iterations = registration_result.loss_log[\"iteration\"].numpy()\n",
    "\n",
    "    num_scales = scales[-1][0] + 1\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=num_scales, figsize=(20, 5))\n",
    "\n",
    "    masks = {}\n",
    "    for scale in range(0, num_scales):\n",
    "        masks[scale] = registration_result.loss_log[\"scale\"] == scale\n",
    "\n",
    "        rmse = registration_result.loss_log[\"inlier_rmse\"][masks[scale]].numpy()\n",
    "        iteration = registration_result.loss_log[\"iteration\"][\n",
    "            masks[scale]].numpy()\n",
    "\n",
    "        title_prefix = \"Scale Index: \" + str(scale)\n",
    "        axes[scale].set_title(title_prefix + \" Inlier RMSE vs Iteration\")\n",
    "        axes[scale].plot(iteration, rmse)\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = source.clone()\n",
    "    target_temp = target.clone()\n",
    "\n",
    "    source_temp.transform(transformation)\n",
    "\n",
    "    # This is patched version for tutorial rendering.\n",
    "    # Use `draw` function for you application.\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [source_temp.to_legacy(),\n",
    "         target_temp.to_legacy()] )\n",
    "    \n",
    "def VisualizePointCloudMovie(pcds):\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcds[0])\n",
    "\n",
    "    i = 1\n",
    "    while not keyboard.is_pressed('esc'):    \n",
    "        if keyboard.is_pressed('right') and i < len(pcds)-1:\n",
    "            vis.clear_geometries()\n",
    "            vis.add_geometry(pcds[i], False)\n",
    "            #vis.update_geometry(pcds[0].transform(transforms[i]), False)\n",
    "            i = i + 1\n",
    "        if keyboard.is_pressed('left') and i > 0:\n",
    "            vis.clear_geometries()\n",
    "            vis.add_geometry(pcds[i], False)\n",
    "            #vis.update_geometry(pcds[0].transform(transforms[i]), False)\n",
    "            i = i - 1\n",
    "            s = time.time()\n",
    "    \n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()  \n",
    "    vis.destroy_window()\n",
    "        \n",
    "def collectframes(picklefile = 'realbag', numframes=300, savebag = False):    \n",
    "    frames = []\n",
    "    for i in range(numframes):\n",
    "        success3d = fg3d.wait_for_frame(im3d)\n",
    "        success2d = fg2d.wait_for_frame(im2d)\n",
    "        if not success2d:\n",
    "            print('2d failed!')\n",
    "        if not success3d:\n",
    "            print('3d failed!')\n",
    "        frames.append((im3d.xyz_image() , im2d.jpeg_image(), im3d.distance_image()))   \n",
    "        #time.sleep(.1)\n",
    "    \n",
    "    if savebag:\n",
    "        with open(picklefile, \"wb\") as fp:\n",
    "            pickle.dump(frames, fp)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de1c5a7-8476-46a2-a009-719282c65ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"device\": {\n",
      "        \"clock\": {\n",
      "            \"currentTime\": 1581090794560201440\n",
      "        },\n",
      "        \"diagnostic\": {\n",
      "            \"temperatures\": [],\n",
      "            \"upTime\": 150000000000\n",
      "        },\n",
      "        \"info\": {\n",
      "            \"device\": \"0301\",\n",
      "            \"deviceTreeBinaryBlob\": \"tegra186-quill-p3310-1000-c03-00-base.dtb\",\n",
      "            \"features\": {},\n",
      "            \"name\": \"\",\n",
      "            \"partNumber\": \"M03975\",\n",
      "            \"productionState\": \"AA\",\n",
      "            \"serialNumber\": \"00020142B090\",\n",
      "            \"vendor\": \"0001\"\n",
      "        },\n",
      "        \"network\": {\n",
      "            \"authorized_keys\": \"\",\n",
      "            \"ipAddressConfig\": 0,\n",
      "            \"macEth0\": \"48:B0:2D:3A:68:01\",\n",
      "            \"macEth1\": \"00:02:01:42:B0:90\",\n",
      "            \"networkSpeed\": 1000,\n",
      "            \"staticIPv4Address\": \"192.168.0.69\",\n",
      "            \"staticIPv4Gateway\": \"192.168.0.201\",\n",
      "            \"staticIPv4SubNetMask\": \"255.255.255.0\",\n",
      "            \"useDHCP\": false\n",
      "        },\n",
      "        \"state\": {\n",
      "            \"errorMessage\": \"\",\n",
      "            \"errorNumber\": \"\"\n",
      "        },\n",
      "        \"swVersion\": {\n",
      "            \"kernel\": \"4.9.140-l4t-r32.4+gc35f5eb9d1d9\",\n",
      "            \"l4t\": \"r32.4.3\",\n",
      "            \"os\": \"0.13.13-221\",\n",
      "            \"schema\": \"v0.1.0\",\n",
      "            \"swu\": \"0.15.12\"\n",
      "        }\n",
      "    },\n",
      "    \"ports\": {\n",
      "        \"port0\": {\n",
      "            \"acquisition\": {\n",
      "                \"exposureLong\": 5000,\n",
      "                \"exposureShort\": 400,\n",
      "                \"framerate\": 20,\n",
      "                \"offset\": 0.0,\n",
      "                \"version\": {\n",
      "                    \"major\": 0,\n",
      "                    \"minor\": 0,\n",
      "                    \"patch\": 0\n",
      "                }\n",
      "            },\n",
      "            \"data\": {\n",
      "                \"algoDebugConfig\": {},\n",
      "                \"availablePCICOutput\": [],\n",
      "                \"pcicTCPPort\": 50010\n",
      "            },\n",
      "            \"info\": {\n",
      "                \"device\": \"3101\",\n",
      "                \"deviceTreeBinaryBlobOverlay\": \"001-irs2381c.dtbo\",\n",
      "                \"features\": {\n",
      "                    \"fov\": {\n",
      "                        \"horizontal\": 105,\n",
      "                        \"vertical\": 78\n",
      "                    },\n",
      "                    \"resolution\": {\n",
      "                        \"height\": 172,\n",
      "                        \"width\": 224\n",
      "                    },\n",
      "                    \"type\": \"3D\"\n",
      "                },\n",
      "                \"name\": \"\",\n",
      "                \"partNumber\": \"M03969\",\n",
      "                \"productionState\": \"AA\",\n",
      "                \"sensor\": \"IRS2381C\",\n",
      "                \"sensorID\": \"IRS2381C_105x78_4x2W_110x90_C7\",\n",
      "                \"serialNumber\": \"000000000865\",\n",
      "                \"vendor\": \"0001\"\n",
      "            },\n",
      "            \"mode\": \"standard_range4m\",\n",
      "            \"processing\": {\n",
      "                \"diParam\": {\n",
      "                    \"anfFilterSizeDiv2\": 2,\n",
      "                    \"enableDynamicSymmetry\": true,\n",
      "                    \"enableStraylight\": true,\n",
      "                    \"enableTemporalFilter\": true,\n",
      "                    \"excessiveCorrectionThreshAmp\": 0.3,\n",
      "                    \"excessiveCorrectionThreshDist\": 0.08,\n",
      "                    \"maxDistNoise\": 0.02,\n",
      "                    \"maxSymmetry\": 0.4,\n",
      "                    \"medianSizeDiv2\": 0,\n",
      "                    \"minAmplitude\": 20.0,\n",
      "                    \"minReflectivity\": 0.0,\n",
      "                    \"mixedPixelFilterMode\": 1,\n",
      "                    \"mixedPixelThresholdRad\": 0.15\n",
      "                },\n",
      "                \"extrinsicHeadToUser\": {\n",
      "                    \"rotX\": 0.0,\n",
      "                    \"rotY\": 0.0,\n",
      "                    \"rotZ\": 0.0,\n",
      "                    \"transX\": 0.0,\n",
      "                    \"transY\": 0.0,\n",
      "                    \"transZ\": 0.0\n",
      "                },\n",
      "                \"version\": {\n",
      "                    \"major\": 0,\n",
      "                    \"minor\": 0,\n",
      "                    \"patch\": 0\n",
      "                }\n",
      "            },\n",
      "            \"state\": \"RUN\"\n",
      "        },\n",
      "        \"port2\": {\n",
      "            \"acquisition\": {\n",
      "                \"framerate\": 20,\n",
      "                \"version\": {\n",
      "                    \"major\": 0,\n",
      "                    \"minor\": 0,\n",
      "                    \"patch\": 0\n",
      "                }\n",
      "            },\n",
      "            \"data\": {\n",
      "                \"algoDebugConfig\": {},\n",
      "                \"availablePCICOutput\": [],\n",
      "                \"pcicTCPPort\": 50012\n",
      "            },\n",
      "            \"info\": {\n",
      "                \"device\": \"2301\",\n",
      "                \"deviceTreeBinaryBlobOverlay\": \"001-ov9782.dtbo\",\n",
      "                \"features\": {\n",
      "                    \"fov\": {\n",
      "                        \"horizontal\": 127,\n",
      "                        \"vertical\": 80\n",
      "                    },\n",
      "                    \"resolution\": {\n",
      "                        \"height\": 800,\n",
      "                        \"width\": 1280\n",
      "                    },\n",
      "                    \"type\": \"2D\"\n",
      "                },\n",
      "                \"name\": \"\",\n",
      "                \"partNumber\": \"M03969\",\n",
      "                \"productionState\": \"AA\",\n",
      "                \"sensor\": \"OV9782\",\n",
      "                \"sensorID\": \"OV9782_127x80_noIllu_Csample\",\n",
      "                \"serialNumber\": \"000000000865\",\n",
      "                \"vendor\": \"0001\"\n",
      "            },\n",
      "            \"mode\": \"experimental_autoexposure2D\",\n",
      "            \"processing\": {\n",
      "                \"extrinsicHeadToUser\": {\n",
      "                    \"rotX\": 0.0,\n",
      "                    \"rotY\": 0.0,\n",
      "                    \"rotZ\": 0.0,\n",
      "                    \"transX\": 0.0,\n",
      "                    \"transY\": 0.0,\n",
      "                    \"transZ\": 0.0\n",
      "                },\n",
      "                \"version\": {\n",
      "                    \"major\": 0,\n",
      "                    \"minor\": 0,\n",
      "                    \"patch\": 0\n",
      "                }\n",
      "            },\n",
      "            \"state\": \"RUN\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "o3r = O3RCamera()\n",
    "config = o3r.get()\n",
    "config['ports']['port0']['acquisition']['framerate'] = 20\n",
    "config['ports']['port2']['acquisition']['framerate'] = 20\n",
    "config['ports']['port0']['state'] = 'RUN'\n",
    "config['ports']['port2']['state'] = 'RUN'\n",
    "#config['ports']['port0']['processing']['diParam']['maxDistNoise'] = 0.02\n",
    "fg3d = FrameGrabber(o3r, 10, 50010)\n",
    "im3d = ImageBuffer()\n",
    "fg2d = FrameGrabber(o3r, 10, 50012)\n",
    "im2d = ImageBuffer()\n",
    "\n",
    "o3r.set(config)\n",
    "print(json.dumps(config,indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861775e6-4939-4e6f-8a3d-e0300183bf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE Collecting 17.048710107803345\n"
     ]
    }
   ],
   "source": [
    "#time.sleep(15)\n",
    "s = time.time()\n",
    "#frames = loadpickle('bag4')\n",
    "#frames = loadpickle('realbag')\n",
    "frames = collectframes('realbag', 300, True)\n",
    "print('DONE Collecting ' + str(time.time() - s))\n",
    "\n",
    "s = time.time()\n",
    "config = loadpickle('rgb_camera_config')\n",
    "\n",
    "pcds, maskpcds = load_point_clouds(frames, config=config)\n",
    "print(time.time() - s) \n",
    "#o3d.visualization.draw_geometries(pcds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f36995-c403-4ef8-987f-4a327519bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "VisualizePointCloudMovie(pcds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17eeb0-a769-4876-b94e-82d6081a0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def moveimage(pcd, direction, left, right, up, down):    \n",
    "    rgb = frames[i][1]\n",
    "    rgb = cv2.imdecode(rgb, cv2.IMREAD_UNCHANGED)\n",
    "    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB) \n",
    "    rgb = undistort(rgb,config)\n",
    "    \n",
    "    padup = np.zeros((100,rgb.shape[1],3))\n",
    "    paddown = np.zeros((100,rgb.shape[1],3))\n",
    "    \n",
    "    rgb = np.concatenate([padup, rgb, paddown], axis=0)      \n",
    "    \n",
    "    if direction == 'left':\n",
    "        left = left - 1\n",
    "        right = right - 1\n",
    "    elif direction == 'right':\n",
    "        left = left + 1\n",
    "        right = right + 1  \n",
    "    elif direction == 'up':\n",
    "        up = up - 1\n",
    "        down = down - 1   \n",
    "    elif direction == 'down':\n",
    "        up = up + 1\n",
    "        down = down + 1\n",
    "    elif direction == 'a':\n",
    "        left = left - 1\n",
    "        right = right + 1\n",
    "    elif direction == 's':\n",
    "        left = left + 1\n",
    "        right = right - 1\n",
    "    elif direction == 'q':\n",
    "        up = up - 1\n",
    "        down = down + 1\n",
    "    elif direction == 'w':\n",
    "        up = up + 1\n",
    "        down = down - 1       \n",
    "    \n",
    "    \n",
    "    rgb = rgb[up : down, left : right] \n",
    "    rgb = cv2.resize(rgb, (224,172), interpolation = cv2.INTER_AREA)\n",
    "    rgb = rgb.reshape((rgb.shape[0] * rgb.shape[1], 3))\n",
    "    rgb = rgb/255 \n",
    "    pcd.colors = o3d.utility.Vector3dVector(rgb)\n",
    "    \n",
    "    return pcd, left, right, up, down\n",
    "\n",
    "up = 64\n",
    "down = -90\n",
    "left = 83\n",
    "right = -109\n",
    "s = time.time()\n",
    "i = 1\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "pcdscal = [copy.deepcopy(x) for x in pcds]\n",
    "\n",
    "vis.add_geometry(copy.deepcopy(pcdscal[i]))\n",
    "config = loadpickle('rgb_camera_config')\n",
    "\n",
    "while not keyboard.is_pressed('esc'):  \n",
    "   \n",
    "    if keyboard.is_pressed('up'): \n",
    "        pcdscal[i], left, right, up, down = moveimage(pcdscal[i], 'up', left, right, up, down)\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcdscal[i], False)\n",
    "    if keyboard.is_pressed('down'):\n",
    "        pcdscal[i], left, right, up, down = moveimage(pcdscal[i], 'down', left, right, up, down)\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcdscal[i], False)\n",
    "    if keyboard.is_pressed('left'): \n",
    "        pcdscal[i], left, right, up, down = moveimage(pcdscal[i], 'left', left, right, up, down)\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcdscal[i], False)\n",
    "    if keyboard.is_pressed('right'): \n",
    "        pcdscal[i], left, right, up, down = moveimage(pcdscal[i], 'right', left, right, up, down)\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcdscal[i], False)\n",
    "    \n",
    "    if keyboard.is_pressed('a'): \n",
    "        pcdscal[i], left, right, up, down = moveimage(pcdscal[i], 'a', left, right, up, down)\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcdscal[i], False)\n",
    "        \n",
    "    if keyboard.is_pressed('s'): \n",
    "        pcdscal[i], left, right, up, down = moveimage(pcdscal[i], 's', left, right, up, down)\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcdscal[i], False)\n",
    "        \n",
    "    if keyboard.is_pressed('q'): \n",
    "        pcdscal[i], left, right, up, down = moveimage(pcdscal[i], 'q', left, right, up, down)\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcdscal[i], False)\n",
    "        \n",
    "    if keyboard.is_pressed('w'): \n",
    "        pcdscal[i], left, right, up, down = moveimage(pcdscal[i], 'w', left, right, up, down)\n",
    "        vis.clear_geometries()\n",
    "        vis.add_geometry(pcdscal[i], False)\n",
    "        \n",
    "    if keyboard.is_pressed('space') and i < len(pcdscal)-1:\n",
    "            pcdscal[i], left, right, up, down = moveimage(pcdscal[i], '', left, right, up, down)\n",
    "            vis.clear_geometries()            \n",
    "            vis.add_geometry(pcdscal[i], False)\n",
    "            i = i + 1\n",
    "    if keyboard.is_pressed('backspace') and i > 0:\n",
    "            pcdscal[i], left, right, up, down = moveimage(pcdscal[i], '', left, right, up, down)\n",
    "            vis.clear_geometries()\n",
    "            vis.add_geometry(pcdscal[i], False)\n",
    "            i = i - 1\n",
    "            s = time.time()\n",
    "            \n",
    "    moveimage(pcdscal[i], '', left, right, up, down)\n",
    "    \n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "print(up)\n",
    "print(down)\n",
    "print(left)\n",
    "print(right)\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8621ebe-4e7b-44a9-9e33-eaa137c3b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd8cc2a-07d2-42f5-8db8-e6a6bd74f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ca945-bf86-42bf-a6ab-aa466d3391d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "newpcd = []\n",
    "cnt = 1\n",
    "checkevery = 5000\n",
    "for i in range(0,400):     \n",
    "    pcd = pcds[i].voxel_down_sample(voxel_size=0.01)\n",
    "    \n",
    "    plane_model, inliers = pcd.segment_plane(distance_threshold=0.04, ransac_n=3, num_iterations=1000)\n",
    "    [a, b, c, d] = plane_model\n",
    "    \n",
    "    if cnt % checkevery == 0:\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "        \n",
    "    inlier_cloud = pcd.select_by_index(inliers)\n",
    "    inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "    pcd = pcd.select_by_index(inliers, invert=True)\n",
    "    \n",
    "    if cnt % checkevery == 0:\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    \n",
    "    pcd, o = pcd.remove_radius_outlier(15, .1, True)\n",
    "    \n",
    "    if cnt % checkevery == 0:\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    \n",
    "    #with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    labels = np.array(pcd.cluster_dbscan(eps=0.13, min_points=50))  \n",
    "       \n",
    "    unique, counts = np.unique(labels[labels > -1], return_counts=True)    \n",
    "    \n",
    "    idxs = np.where(labels == unique[np.argmax(counts)])[0]\n",
    "    \n",
    "    cpcd = pcd.select_by_index(idxs)\n",
    "    \n",
    "    #cpcd, o = cpcd.remove_radius_outlier(15, .1, True)\n",
    "        \n",
    "    max_label = labels.max()\n",
    "    \n",
    "    colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "    colors[labels < 0] = 0\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "    \n",
    "    \n",
    "    if cnt % checkevery == 0:    \n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    if cnt % checkevery == 0:\n",
    "        o3d.visualization.draw_geometries([cpcd])\n",
    "    \n",
    "    pcd = cpcd\n",
    "    \n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.25, max_nn=30))\n",
    "    pcd.orient_normals_towards_camera_location()\n",
    "    newpcd.append(pcd)\n",
    "    cnt = cnt + 1      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9cadd-bb3e-4c46-a09e-898884c24a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#source = pcds[0]\n",
    "#target = pcds[1]\n",
    "source = copy.deepcopy(newpcd[0])\n",
    "target = copy.deepcopy(newpcd[10])\n",
    "\n",
    "source = source.paint_uniform_color([1.0, 0, 0])\n",
    "target = target.paint_uniform_color([0, 0, 1.0])\n",
    "\n",
    "o3d.visualization.draw_geometries([source, target])\n",
    "\n",
    "voxel_sizes = o3d.utility.DoubleVector([0.15, 0.05, 0.025])\n",
    "\n",
    "# List of Convergence-Criteria for Multi-Scale ICP:\n",
    "criteria_list = [\n",
    "    o3d.t.pipelines.registration.ICPConvergenceCriteria(relative_fitness=0.0001,\n",
    "                                relative_rmse=0.0001,\n",
    "                                max_iteration=20),\n",
    "    o3d.t.pipelines.registration.ICPConvergenceCriteria(0.0001, 0.0001, 15),\n",
    "    o3d.t.pipelines.registration.ICPConvergenceCriteria(0.00001, 0.00001, 10)\n",
    "]\n",
    "\n",
    "# `max_correspondence_distances` for Multi-Scale ICP (o3d.utility.DoubleVector):\n",
    "max_correspondence_distances = o3d.utility.DoubleVector([0.4, 0.14, 0.05])\n",
    "\n",
    "# Initial alignment or source to target transform.\n",
    "init_source_to_target = o3d.core.Tensor.eye(4, o3d.core.Dtype.Float32)\n",
    "\n",
    "# Select the `Estimation Method`, and `Robust Kernel` (for outlier-rejection).\n",
    "#estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "estimation = o3d.t.pipelines.registration.TransformationEstimationForColoredICP()\n",
    "#estimation = o3d.t.pipelines.registration.TransformationEstimationForGeneralizedICP()\n",
    "# mu, sigma = 0, 1 \n",
    "# estimation = o3d.t.pipelines.registration.TransformationEstimationForColoredICP(o3d.t.pipelines.registration.robust_kernel.RobustKernel(\n",
    "#             o3d.t.pipelines.registration.robust_kernel.RobustKernelMethod.TukeyLoss, sigma))\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "source = o3d.t.geometry.PointCloud().from_legacy(source)\n",
    "target = o3d.t.geometry.PointCloud().from_legacy(target)\n",
    "\n",
    "registration_ms_icp = o3d.t.pipelines.registration.multi_scale_icp(source, target, voxel_sizes,\n",
    "                                           criteria_list,\n",
    "                                           max_correspondence_distances,\n",
    "                                           estimation_method = estimation,\n",
    "                                           save_loss_log=True)\n",
    "\n",
    "ms_icp_time = time.time() - s\n",
    "print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "\n",
    "draw_registration_result(source,target,registration_ms_icp.transformation)\n",
    "\n",
    "plot_rmse(registration_ms_icp)\n",
    "plot_scale_wise_rmse(registration_ms_icp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a97637-c24a-460c-b090-bd5e1c5eef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiscaleicp(s, t):\n",
    "    voxel_sizes = o3d.utility.DoubleVector([0.1, 0.05, 0.025])\n",
    "    criteria_list = [\n",
    "        o3d.t.pipelines.registration.ICPConvergenceCriteria(relative_fitness=0.0001, relative_rmse=0.0001, max_iteration=20),\n",
    "        o3d.t.pipelines.registration.ICPConvergenceCriteria(0.00001, 0.00001, 15),\n",
    "        o3d.t.pipelines.registration.ICPConvergenceCriteria(0.000001, 0.000001, 10),\n",
    "    ]\n",
    "\n",
    "    max_correspondence_distances = o3d.utility.DoubleVector([0.3, 0.14, 0.07])\n",
    "\n",
    "\n",
    "    # Select the `Estimation Method`, and `Robust Kernel` (for outlier-rejection).\n",
    "    #estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    #estimation = o3d.t.pipelines.registration.TransformationEstimationForColoredICP()\n",
    "    mu, sigma = 0, 1 \n",
    "    estimation = o3d.t.pipelines.registration.TransformationEstimationForColoredICP(o3d.t.pipelines.registration.robust_kernel.RobustKernel(\n",
    "                o3d.t.pipelines.registration.robust_kernel.RobustKernelMethod.TukeyLoss, sigma))\n",
    "    \n",
    "    registration_ms_icp = o3d.t.pipelines.registration.multi_scale_icp(s, t, voxel_sizes,\n",
    "                                           criteria_list,\n",
    "                                           max_correspondence_distances,\n",
    "                                           estimation_method = estimation,\n",
    "                                           save_loss_log=True)\n",
    "    \n",
    "    return registration_ms_icp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a079c9-be3f-4e36-81ca-613de53116e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds = [o3d.t.geometry.PointCloud().from_legacy(copy.deepcopy(i)) for i in newpcd]\n",
    "\n",
    "tottime = time.time()\n",
    "master =  pcds[0].clone()\n",
    "\n",
    "\n",
    "masters = []      \n",
    "source_cuda = 0\n",
    "toofar = False\n",
    "end = 250\n",
    "i = 0\n",
    "while i < end:    \n",
    "    s = time.time() \n",
    "        \n",
    "    target_cuda = pcds[i]\n",
    "    \n",
    "    registration_ms_icp = multiscaleicp(pcds[source_cuda], target_cuda)\n",
    "    #registration_ms_icp = multiscaleicp(master, target_cuda)\n",
    "    #registration_ms_icp = multiscaleicp(master, target_cuda) \n",
    "\n",
    "    ms_icp_time = time.time() - s\n",
    "    scale = registration_ms_icp.loss_log['scale'].numpy()\n",
    "    fitness = registration_ms_icp.loss_log['fitness'].numpy()\n",
    "    rmse = registration_ms_icp.loss_log['inlier_rmse'].numpy()\n",
    "    m = np.hstack([scale, fitness])\n",
    "    m = m[m[:,0] == 2,:]\n",
    "    m = m[0][1]\n",
    "    e = np.hstack([scale, rmse])\n",
    "    e = e[e[:,0] == 2,:]\n",
    "    e = e[0][1]\n",
    "    \n",
    "    #print(e)\n",
    "    if m > .95 or e < .022:# or m < .8:#and not toofar:  \n",
    "        i = i + 1\n",
    "        continue\n",
    "        \n",
    "    # if toofar:\n",
    "    #     toofar = False\n",
    "    \n",
    "    print(str(source_cuda) + ' ' + str(i))\n",
    "    print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "    print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "    print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "    \n",
    "    if registration_ms_icp.fitness < .9:  \n",
    "        print('************************************************** ' + str(source_cuda) + ' '+ str(i))\n",
    "        #master = master.voxel_down_sample(voxel_size=0.025)\n",
    "#         registration_ms_icp = multiscaleicp(master, target_cuda)\n",
    "#         print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "#         print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "#         pcds[source_cuda].transform(registration_ms_icp.transformation)\n",
    "#         target_cuda = o3d.t.geometry.PointCloud().from_legacy(target_cuda.to_legacy().paint_uniform_color([1.0, 0, 0]))\n",
    "        \n",
    "        # toofar = True\n",
    "        # i = i-1\n",
    "        # continue\n",
    "    \n",
    "    \n",
    "    #transforms.append(registration_ms_icp.transformation)        \n",
    "    master =  master.transform(registration_ms_icp.transformation) + target_cuda\n",
    "    #o3d.visualization.draw_geometries([master.to_legacy()])       \n",
    "    #masters.append(pcds[source_cuda].transform(registration_ms_icp.transformation).to_legacy())\n",
    "    #masters.append(master.clone().to_legacy())\n",
    "    source_cuda = i\n",
    "    i = i + 1\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90636c17-5da9-4087-b0ea-9b6806ac41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([target_cuda.to_legacy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc08774-a7f7-4f39-8861-3bc55be971e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([master.to_legacy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3291e-6c7f-4eed-bf20-c3bef7b9d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(masters[0])\n",
    "\n",
    "s = time.time()\n",
    "i = 1\n",
    "while not keyboard.is_pressed('esc'):    \n",
    "    if time.time() - s > .5 and i < len(masters):\n",
    "        vis.add_geometry(masters[i], False)\n",
    "        #vis.update_geometry(pcds[0].transform(transforms[i]), False)\n",
    "        i = i + 1\n",
    "        s = time.time()\n",
    "    \n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()  \n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49735d-4ac2-4314-b4dc-610706bde959",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds = [o3d.t.geometry.PointCloud().from_legacy(i) for i in newpcd]\n",
    "tottime = time.time()\n",
    "master = None\n",
    "#hotpink =  o3d.t.geometry.PointCloud().from_legacy(maskpcds[0])\n",
    "\n",
    "\n",
    "step = 30\n",
    "#combinedpc =  o3d.geometry.PointCloud()\n",
    "for i in range(0, 300, step):    \n",
    "    s = time.time()\n",
    "    print(str(i) + \" \" + str(i+step+1))\n",
    "    graphpcs = pcds[i:i+step+1]\n",
    "    #print(len(graphpcs))\n",
    "    pose_graph = full_registration(graphpcs)\n",
    "    #print(len(pose_graph.nodes))\n",
    "    print(\"Optimizing PoseGraph ...\")\n",
    "    option = o3d.pipelines.registration.GlobalOptimizationOption(max_correspondence_distance=max_correspondence_distances[2],\n",
    "                                                                 edge_prune_threshold=0.25,\n",
    "                                                                 reference_node=step)\n",
    "    \n",
    "    o3d.pipelines.registration.global_optimization(pose_graph,\n",
    "        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "        o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n",
    "        option)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # with o3d.utility.VerbosityContextManager(\n",
    "    #         o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    #     o3d.pipelines.registration.global_optimization(\n",
    "    #         pose_graph,\n",
    "    #         o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "    #         o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n",
    "    #         option)\n",
    "    \n",
    "    \n",
    "    print(\"Transform points and display\")\n",
    "    \n",
    "    master.transform(pose_graph.nodes[0].pose)\n",
    "    for point_id in range(1,len(graphpcs)):        \n",
    "        graphpcs[point_id].transform(pose_graph.nodes[point_id].pose)  \n",
    "    \n",
    "    \n",
    "        master = master + graphpcs[point_id]\n",
    "        #legacy.append(graphpcs[point_id].to_legacy())\n",
    "    #o3d.visualization.draw_geometries([ x.to_legacy() for x in graphpcs ] )\n",
    "    #o3d.visualization.draw_geometries([master.to_legacy()])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # registration_ms_icp = o3d.t.pipelines.registration.multi_scale_icp(source_cuda, target_cuda,\n",
    "    #                                        voxel_sizes, criteria_list,\n",
    "    #                                        max_correspondence_distances, estimation_method = estimation)#, init_source_to_target = result_ransac.transformation)#, save_loss_log=False)#,\n",
    "    #                                        #result_ransac.transformation, estimation,\n",
    "    #                                        #save_loss_log)\n",
    "\n",
    "    # source_cuda = source_cuda.cpu()\n",
    "    # target_cuda = target_cuda.cpu()\n",
    "    ms_icp_time = time.time() - s\n",
    "    print(\"Time taken Pose Estimation for \" + str(step) + \" frames: \", ms_icp_time)\n",
    "    #print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "    #print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "    \n",
    "    #master = master.transform(registration_ms_icp.transformation) + target_cuda \n",
    "    #hotpink = hotpink.transform(registration_ms_icp.transformation) + o3d.t.geometry.PointCloud().from_legacy(maskpcds[i]) \n",
    "        \n",
    "    \n",
    "print(time.time() - tottime)\n",
    "master = master.to_legacy()\n",
    "#hotpink = hotpink.to_legacy()\n",
    "o3d.visualization.draw_geometries([master])\n",
    "#o3d.visualization.draw_geometries([hotpink])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abba16-78c1-4649-b1e2-57f673be2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([newpcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af18528-ee0f-47c6-9f43-e9025d76b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "\n",
    "    demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "    source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "    target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4154f8-4dfd-4ffd-9148-522614a8444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 30\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    #pcd_down.orient_normals_consistent_tangent_plane(30)\n",
    "    pcd_down.orient_normals_towards_camera_location()\n",
    "    radius_feature = voxel_size * 2\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=30))\n",
    "    print(pcd_fpfh)\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba21ae-a84e-4786-ba33-29454569098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a079653-a6d0-451a-98c6-b37eb3ecd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = 0.2  # means 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcb821-853f-4bcb-beb7-454b0a6fa724",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0164e-c804-4b66-ad09-0f9f45d5efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    # result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    #     source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "    #     distance_threshold,\n",
    "    #     o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "    #     3, [\n",
    "    #         o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "    #         o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "    #     ], o3d.pipelines.registration.RANSACConvergenceCriteria(1000000, 0.999))\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        2, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(1000000, 0.999))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184b454-d35e-46d5-bdf0-a14205116b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_fast_global_registration(source_down, target_down, source_fpfh,\n",
    "                                     target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1\n",
    "    print(\":: Apply fast global registration with distance threshold %.3f\" \\\n",
    "            % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        o3d.pipelines.registration.FastGlobalRegistrationOption(maximum_correspondence_distance=distance_threshold))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edb479-c4eb-4c4c-8a9b-ffd92c755414",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcds[0], pcds[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c33e9-28ca-4f40-8c14-91b38dd95ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voxel_size = .02\n",
    "pcd_down_s, pcd_fpfh_s = preprocess_point_cloud(copy.deepcopy(pcds[0]), voxel_size)    \n",
    "pcd_down_t, pcd_fpfh_t = preprocess_point_cloud(copy.deepcopy(pcds[100]), voxel_size)\n",
    "    \n",
    "o3d.visualization.draw_geometries([pcd_down_s, pcd_down_t])\n",
    "    \n",
    "result_ransac = execute_global_registration(pcd_down_s, pcd_down_t , pcd_fpfh_s, pcd_fpfh_t, voxel_size)\n",
    "#\n",
    "#result_ransac = execute_fast_global_registration(pcd_down_s, pcd_down_t,\n",
    "#                                            pcd_fpfh_s, pcd_fpfh_t,\n",
    "#                                            voxel_size)\n",
    "\n",
    "print(result_ransac)\n",
    "o3d.visualization.draw_geometries([copy.deepcopy(pcds[0]).transform(result_ransac.transformation), pcds[100]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2dd9e1-e692-4829-bf7c-b4f1d9d1983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(newpcd[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d12936-7851-48f3-8a04-99ffb1243dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(masters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8b8df-2d01-4ad4-9efe-f5bde6b7c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds = newpcd \n",
    "tottime = time.time()\n",
    "#master =  o3d.t.geometry.PointCloud().from_legacy(pcds[0])\n",
    "master = None\n",
    "#hotpink =  o3d.t.geometry.PointCloud().from_legacy(maskpcds[0])\n",
    "#master.estimate_normals(max_nn=30, radius=.05)\n",
    "\n",
    "# vis.clear_geometries()\n",
    "# vis.add_geometry(master.to_legacy())\n",
    "\n",
    "#updatevis(vis, master.to_legacy())\n",
    "transforms =[]\n",
    "masters = []      \n",
    "for i in range(0, 100):    \n",
    "    s = time.time()   \n",
    "    \n",
    "    \n",
    "    #source_cuda = master\n",
    "    source_cuda = o3d.t.geometry.PointCloud().from_legacy(pcds[i-1])\n",
    "    #source_cuda = source_cuda.cuda(0) \n",
    "    \n",
    "    target_cuda = o3d.t.geometry.PointCloud().from_legacy(pcds[i])\n",
    "    #target_cuda = target_cuda.cuda(0)  \n",
    "    \n",
    "    \n",
    "#     pcd_down_s, pcd_fpfh_s = preprocess_point_cloud(source_cuda, 0.01)\n",
    "    \n",
    "#     pcd_down_t, pcd_fpfh_t = preprocess_point_cloud(target_cuda, 0.01)\n",
    "    \n",
    "#     result_ransac = execute_fast_global_registration(pcd_down_s, pcd_down_t , pcd_fpfh_s, pcd_fpfh_t, 0.01)\n",
    "    \n",
    "    \n",
    "    \n",
    "    criteria = o3d.t.pipelines.registration.ICPConvergenceCriteria(relative_fitness=0.000001,\n",
    "                                       relative_rmse=0.000001,\n",
    "                                       max_iteration=1000)\n",
    "    \n",
    "    registration_ms_icp = o3d.t.pipelines.registration.icp(source_cuda, target_cuda, .1,\n",
    "                             estimation_method =estimation, criteria=criteria, voxel_size=0.01)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     registration_ms_icp = o3d.t.pipelines.registration.multi_scale_icp(master, target_cuda,\n",
    "#                                            voxel_sizes, criteria_list,\n",
    "#                                            max_correspondence_distances, estimation_method = estimation)#, init_source_to_target = result_ransac.transformation)#, save_loss_log=False)#,\n",
    "    #print(  result_ransac.transformation)                                     \n",
    "\n",
    "    #source_cuda = source_cuda.cpu()\n",
    "    #target_cuda = target_cuda.cpu()\n",
    "    ms_icp_time = time.time() - s\n",
    "    \n",
    "    \n",
    "    # if registration_ms_icp.fitness < .99:\n",
    "    #     s = source_cuda.to_legacy()\n",
    "    #     s.paint_uniform_color([1.0, 0, 0])\n",
    "    #     t = target_cuda.to_legacy()\n",
    "    #     t.paint_uniform_color([0, 0, 1.0])\n",
    "    #     vis.add_geometry(t, False)\n",
    "        \n",
    "    \n",
    "    print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "    print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "    print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "    \n",
    "    if master == None:\n",
    "        master = target_cuda\n",
    "    else:\n",
    "        transforms.append(result_ransac.transformation)\n",
    "        master = master.transform(result_ransac.transformation)\n",
    "        master = master + target_cuda\n",
    "        #master = master + target_cuda\n",
    "        #master = master.transform(registration_ms_icp.transformation) + target_cuda\n",
    "    masters.append(copy.deepcopy(source_cuda.transform(result_ransac.transformation).to_legacy()))\n",
    "    #master = master.voxel_down_sample(voxel_size=0.01)\n",
    "    #hotpink = hotpink.transform(registration_ms_icp.transformation) + o3d.t.geometry.PointCloud().from_legacy(maskpcds[i]) \n",
    "    #time.sleep(10)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b70642-2c31-41e9-aeb9-0d0c804605a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(masters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f93d8a-f39b-45a4-9246-c2d7cd8dd6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(transforms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824ec01-dce8-446c-8bb9-fa6ca459978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(masters[0])\n",
    "\n",
    "s = time.time()\n",
    "i = 1\n",
    "while not keyboard.is_pressed('esc'):    \n",
    "    if time.time() - s > .5 and i < len(masters):\n",
    "        vis.add_geometry(masters[i], False)\n",
    "        #vis.update_geometry(pcds[0].transform(transforms[i]), False)\n",
    "        i = i + 1\n",
    "        s = time.time()\n",
    "    \n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()  \n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5beb6e5-9faa-400a-918c-03d886b90174",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = copy.deepcopy(hotpink)\n",
    "pcd = pcd.voxel_down_sample(voxel_size=0.025)\n",
    "plane_model, inliers = pcd.segment_plane(distance_threshold=0.2,\n",
    "                                         ransac_n=3,\n",
    "                                         num_iterations=1000)\n",
    "[a, b, c, d] = plane_model\n",
    "print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "\n",
    "inlier_cloud = pcd.select_by_index(inliers)\n",
    "inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "o3d.visualization.draw_geometries([outlier_cloud])\n",
    "#o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223f489-6630-403b-b665-d62380b86562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plane_model, inliers = outlier_cloud.segment_plane(distance_threshold=0.08,\n",
    "                                         ransac_n=3,\n",
    "                                         num_iterations=1000)\n",
    "[a, b, c, d] = plane_model\n",
    "print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "\n",
    "inlier_cloud = outlier_cloud.select_by_index(inliers)\n",
    "inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "outlier_cloud = outlier_cloud.select_by_index(inliers, invert=True)\n",
    "o3d.visualization.draw_geometries([outlier_cloud])\n",
    "#o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ac9c7-6c4b-4e1a-96ff-fd79a4a4d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pinkcolors = np.asarray(outlier_cloud.colors)\n",
    "pinkpoints = np.asarray(outlier_cloud.points)\n",
    "pcolors = pinkcolors * 255\n",
    "pink = np.where(pcolors[:,0] == 255)\n",
    "hotpoints = pinkpoints[pink]\n",
    "hotcolors = pinkcolors[pink]\n",
    "hotpink2 = o3d.geometry.PointCloud()        \n",
    "hotpink2.points = o3d.utility.Vector3dVector(hotpoints)    \n",
    "hotpink2.colors = o3d.utility.Vector3dVector(hotcolors)    \n",
    "o3d.visualization.draw_geometries([hotpink2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c983f14-480b-4772-a639-dab885ac3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpink2, o = hotpink2.remove_radius_outlier(15, .05,True)\n",
    "o3d.visualization.draw_geometries([hotpink2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8e114-33b2-4778-a7b8-c170c80350f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pcd = outlier_cloud.voxel_down_sample(voxel_size=0.025)\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    labels = np.array(pcd.cluster_dbscan(eps=0.1, min_points=30, print_progress=True))\n",
    "\n",
    "max_label = labels.max()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "colors[labels < 0] = 0\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114351b-f7ed-4146-9536-d17b85033f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Full registration ...\")\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Info) as cm:\n",
    "    pose_graph = full_registration(pcds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87296a-1db9-43dd-8ff5-48bfec92ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimizing PoseGraph ...\")\n",
    "option = o3d.pipelines.registration.GlobalOptimizationOption(\n",
    "    max_correspondence_distance=max_correspondence_distances[2],\n",
    "    edge_prune_threshold=0.25,\n",
    "    reference_node=0)\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    o3d.pipelines.registration.global_optimization(\n",
    "        pose_graph,\n",
    "        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "        o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n",
    "        option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179e972-dfc5-4e97-b29b-d9eb39832a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transform points and display\")\n",
    "legacy = []\n",
    "for point_id in range(len(pcds[:50])):\n",
    "    print(pose_graph.nodes[point_id].pose)\n",
    "    p = copy.deepcopy(pcds[point_id])\n",
    "    p.transform(pose_graph.nodes[point_id].pose)\n",
    "    legacy.append(p)\n",
    "o3d.visualization.draw_geometries(legacy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d771d-842f-41c3-8f20-d99ed4a75502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pcds = load_point_clouds(voxel_size)\n",
    "pcd_combined = o3d.geometry.PointCloud()\n",
    "for point_id in range(len(pcds)):\n",
    "    pcds[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "    pcd_combined += pcds[point_id]\n",
    "pcd_combined_down = pcd_combined.voxel_down_sample(voxel_size=voxel_size*.5)\n",
    "#o3d.io.write_point_cloud(\"multiway_registration.pcd\", pcd_combined_down)\n",
    "o3d.visualization.draw_geometries([pcd_combined_down],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53acff-2187-4eb1-a443-ea9464a8dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = None\n",
    "for _ in range(5):\n",
    "    voxel_size = 0.05\n",
    "    pcds_down, pcds = load_point_clouds(voxel_size)\n",
    "    #o3d.visualization.draw_geometries(pcds_down)\n",
    "    print(\"Full registration ...\")\n",
    "  \n",
    "    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Info) as cm:\n",
    "        pose_graph = full_registration(pcds_down,\n",
    "                                   max_correspondence_distance_coarse,\n",
    "                                   max_correspondence_distance_fine)\n",
    "    \n",
    "    print(\"Transform points and display\")\n",
    "    for point_id in range(len(pcds_down)):\n",
    "        #print(pose_graph.nodes[point_id].pose)\n",
    "        pcds_down[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "    #o3d.visualization.draw_geometries(pcds_down)\n",
    "    \n",
    "    \n",
    "    pcd_combined = o3d.geometry.PointCloud()\n",
    "    for point_id in range(len(pcds)):\n",
    "        pcds[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "        pcd_combined += pcds[point_id]\n",
    "    pcd_combined_down = pcd_combined.voxel_down_sample(voxel_size=voxel_size*.5)\n",
    "    \n",
    "    if master == None:\n",
    "        master = pcd_combined_down\n",
    "    else:\n",
    "        \n",
    "        source_down, source_fpfh = preprocess_point_cloud(master, voxel_size)\n",
    "        target_down, target_fpfh = preprocess_point_cloud(pcd_combined_down, voxel_size)\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        result_ransac = execute_fast_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    \n",
    "        print(result_ransac)\n",
    "        print(\"Global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "    \n",
    "    \n",
    "    \n",
    "        master.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "        pcd_combined_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    \n",
    "        start = time.time()\n",
    "        result_icp = refine_registration(master, pcd_combined_down, source_fpfh, target_fpfh, voxel_size)\n",
    "        \n",
    "    \n",
    "        master = master.transform(result_icp.transformation)\n",
    "        master = master + pcd_combined_down\n",
    "        master = master.voxel_down_sample(voxel_size=voxel_size*.5)\n",
    "        print(result_icp)\n",
    "        print(\"Point to Plane registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "        # radius_normal = voxel_size * 2\n",
    "        # pcd_combined_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "        # transformation_icp, information_icp = pairwise_registration(master, pcd_combined_down)\n",
    "        # pcd_combined_down = pcd_combined_down.transform(transformation_icp)\n",
    "        # master = master + pcd_combined_down\n",
    "    \n",
    "    \n",
    "    \n",
    "o3d.visualization.draw_geometries([master])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2e680-4387-4e31-b9ad-1e9edf8e6acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad154e-7e8d-403c-bc37-cb48b7f5ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input point-clouds\n",
    "demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "source = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "target = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[1])\n",
    "\n",
    "source_cuda = source.cuda(0)\n",
    "target_cuda = target.cuda(0)\n",
    "s = time.time()\n",
    "\n",
    "registration_ms_icp = treg.multi_scale_icp(source_cuda, target_cuda,\n",
    "                                           voxel_sizes, criteria_list,\n",
    "                                           max_correspondence_distances,\n",
    "                                           init_source_to_target, estimation,\n",
    "                                           save_loss_log)\n",
    "\n",
    "ms_icp_time = time.time() - s\n",
    "print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "\n",
    "draw_registration_result(source.cpu(), target.cpu(),\n",
    "                         registration_ms_icp.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83f30b-594a-4408-b22e-41c708159762",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([master])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e73c7-0bd8-4e4f-83a3-8e6982e6d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pcd = pcd_combined_down\n",
    "\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    labels = np.array(\n",
    "        pcd.cluster_dbscan(eps=0.08, min_points=50, print_progress=True))\n",
    "\n",
    "max_label = labels.max()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "colors[labels < 0] = 0\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "o3d.visualization.draw_geometries([pcd],\n",
    "                                  zoom=0.455,\n",
    "                                  front=[-0.4999, -0.1659, -0.8499],\n",
    "                                  lookat=[2.1813, 2.0619, 2.0999],\n",
    "                                  up=[0.1204, -0.9852, 0.1215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159be34d-0d80-4ac9-bdc1-36cb5f52cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result_original_color(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target],\n",
    "                                      zoom=0.5,\n",
    "                                      front=[-0.2458, -0.8088, 0.5342],\n",
    "                                      lookat=[1.7745, 2.2305, 0.9787],\n",
    "                                      up=[0.3109, -0.5878, -0.7468])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625fc821-40a5-4ebb-bbdf-38926814e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1. Load two point clouds and show initial pose\")\n",
    "demo_colored_icp_pcds = o3d.data.DemoColoredICPPointClouds()\n",
    "source = o3d.io.read_point_cloud(demo_colored_icp_pcds.paths[0])\n",
    "target = o3d.io.read_point_cloud(demo_colored_icp_pcds.paths[1])\n",
    "\n",
    "# draw initial alignment\n",
    "#current_transformation = np.identity(4)\n",
    "#draw_registration_result_original_color(source, target, current_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898f2bc-5d61-4e6b-9854-6636b64fe2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source.points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3aa68-b360-4eb3-828d-bffbd6e1cab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
