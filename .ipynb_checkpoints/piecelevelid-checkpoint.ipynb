{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d6e72-2f83-4a69-bdc5-29076e41cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ifm3dpy import O3RCamera, FrameGrabber, ImageBuffer\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import segmentation_models as sm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124e819-1a1c-469a-848b-2286f41cd4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import segmentation_models as sm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "class HandlingUnitExtractor():\n",
    "    def __init__(self):\n",
    "        model_file = 'best_model_handling_unit.h5'\n",
    "        self.model_img_size = (512, 512)\n",
    "        self.model = sm.Unet('efficientnetb3', classes=1, activation='sigmoid')\n",
    "        self.model.load_weights(model_file) \n",
    "        self.preprocessor = sm.get_preprocessing('efficientnetb3')\n",
    "        \n",
    "    def extract(self, img):\n",
    "        h, w = img.shape[:2]\n",
    "        image = cv2.resize(img, self.model_img_size, interpolation = cv2.INTER_AREA)\n",
    "        image = self.preprocessor(image)\n",
    "        \n",
    "        #t = time.time()\n",
    "        #mask = self.model.predict(np.expand_dims(image, axis=0)).round().squeeze()\n",
    "        mask = self.model(np.expand_dims(image, axis=0)).numpy()\n",
    "        #print(mask)\n",
    "        mask = mask.round().squeeze()\n",
    "        #print(time.time() -t)\n",
    "        mask = cv2.resize(mask, (w, h), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        mask = self.isolate_largest_component(mask)\n",
    "        \n",
    "        return mask.astype(np.uint8)\n",
    "\n",
    "    def isolate_largest_component(self, img):\n",
    "        result = np.zeros((img.shape))\n",
    "        labels, stats = cv2.connectedComponentsWithStats(img.astype(np.uint8), connectivity=8)[1:3]                   \n",
    "        \n",
    "        largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "        result[labels == largest_label] = 255 \n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770306e3-e7a7-4e3b-925b-b0b67258c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(o3d)\n",
    "print(o3d.core.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a744aa-56ad-4be9-98a3-90107302af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3r = O3RCamera()\n",
    "config = o3r.get()\n",
    "config['ports']['port0']['state'] = 'RUN'\n",
    "config['ports']['port2']['state'] = 'RUN'\n",
    "o3r.set(config)\n",
    "print(json.dumps(config,indent=4))\n",
    "\n",
    "fg = FrameGrabber(o3r,10,50010)\n",
    "im = ImageBuffer()\n",
    "fgjpg = FrameGrabber(o3r,10,50012)\n",
    "imjpg = ImageBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51736d1c-c343-4ee6-86f4-122c77cf6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    #print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    #pcd_down = pcd_down.to_legacy()\n",
    "    radius_normal = voxel_size * 2\n",
    "    #print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    #print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def execute_fast_global_registration(source_down, target_down, source_fpfh,\n",
    "                                     target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    #print(\":: Apply fast global registration with distance threshold %.3f\" \\ % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        o3d.pipelines.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    #print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    #print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    #print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result\n",
    "\n",
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    #distance_threshold = voxel_size * 0.4\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    #print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    #print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    #print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_ransac.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "    return result\n",
    "\n",
    "def refine_registrationP2P(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    #print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    #print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    #print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_ransac.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a68d2-63cf-4597-90e9-22d4a816f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source = pointclouds[0]\n",
    "voxel_size = 0.05\n",
    "radius_normal = voxel_size * 2\n",
    "\n",
    "\n",
    "for i in range(1, len(pointclouds)):\n",
    "    pc = pointclouds[i]\n",
    "    target = pc    \n",
    "    \n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "\n",
    "    start = time.time()\n",
    "    #result_ransac = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    \n",
    "    result_ransac = execute_fast_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    \n",
    "    print(result_ransac)\n",
    "    print(\"Global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "    \n",
    "    \n",
    "    \n",
    "    source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    \n",
    "    start = time.time()\n",
    "    result_icp = refine_registration(source, target, source_fpfh, target_fpfh, voxel_size)\n",
    "    print(result_icp)\n",
    "    print(\"Point to Plane registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "    \n",
    "    source = source.transform(result_icp.transformation)\n",
    "    source = source + target\n",
    "    \n",
    "    draw_registration_result(source, target)\n",
    "    print('yo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4bf0ab-8571-410e-9f11-10baa2aa5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = collectframes('benchmark',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3261c-9651-4840-b145-2316694093bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.imdecode(frames[0][1], cv2.IMREAD_UNCHANGED) \n",
    "rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)  \n",
    "rgb = undistort(rgb)\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e68811-d439-48bf-b946-5c1db0ef3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img):\n",
    "    roi = (125, 102, 860, 515)\n",
    "\n",
    "    mtx = np.array([[607.43997952,   0.        , 645.96889836],\n",
    "                    [  0.        , 605.58954233, 391.50563407],\n",
    "                    [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "    dist = np.array([[-0.35962477,  0.16171162, -0.00081826, -0.00444003, -0.03848117]])\n",
    "\n",
    "    newcameramtx = np.array([[408.22506714,   0.        , 558.75454709],\n",
    "                          [  0.        , 390.17321777, 354.4384903 ],\n",
    "                          [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    x, y, w, h = roi\n",
    "    d = dst.copy()\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    return dst\n",
    "\n",
    "def loadpickle(filename = 'bag'):\n",
    "    with open(filename, \"rb\") as fp:\n",
    "            frames = pickle.load(fp)\n",
    "    return frames\n",
    "\n",
    "def collectframes(picklefile = 'bag3', numframes=300):\n",
    "    frames = []\n",
    "    for _ in range(numframes):\n",
    "        success = fg.wait_for_frame(im)\n",
    "        frame = fgjpg.wait_for_frame(imjpg)\n",
    "        dmap = im.distance_image()            \n",
    "        xyz = im.xyz_image()    \n",
    "        jpg = imjpg.jpeg_image()\n",
    "        frames.append((xyz, jpg, dmap))        \n",
    "        \n",
    "    with open(picklefile, \"wb\") as fp:\n",
    "        pickle.dump(frames, fp)\n",
    "    return frames\n",
    "    \n",
    "\n",
    "def load_point_clouds(frames = None, numframes=200, picklefile= 'bag2'):    \n",
    "       \n",
    "        \n",
    "    \n",
    "    pcds = []\n",
    "    maskpcds = []\n",
    "    hue = HandlingUnitExtractor()\n",
    "    for frame in frames:    \n",
    "        rgb = frame[1]\n",
    "        xyz = frame[0]\n",
    "        rgb = cv2.imdecode(rgb, cv2.IMREAD_UNCHANGED) \n",
    "        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)  \n",
    "        # plt.imshow(rgb)\n",
    "        # plt.show()\n",
    "        rgb = undistort(rgb)\n",
    "        \n",
    "        mask = hue.extract(rgb)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB) \n",
    "        mask[:,:,1] = 0\n",
    "        \n",
    "        \n",
    "        mask = mask[:, 95:-95]\n",
    "        rgb = rgb[:, 95:-95]\n",
    "              \n",
    "        #print(rgb.shape)\n",
    "        #plt.imshow(rgb)\n",
    "        #plt.show()\n",
    "        rgb = cv2.resize(rgb, (224,172), interpolation = cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, (224,172), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        \n",
    "        \n",
    "        rgb = rgb.reshape((rgb.shape[0] * rgb.shape[1], 3))\n",
    "        rgb = rgb/255\n",
    "        \n",
    "        mask = mask.reshape((mask.shape[0] * mask.shape[1], 3))\n",
    "        mask = mask/255\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        xyz = xyz.reshape((xyz.shape[0] * xyz.shape[1], 3))     \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        pcl = o3d.geometry.PointCloud()        \n",
    "        pcl.points = o3d.utility.Vector3dVector(xyz)    \n",
    "        pcl.colors = o3d.utility.Vector3dVector(rgb)         \n",
    "        pcds.append(pcl)    \n",
    "        \n",
    "        maskpcl = o3d.geometry.PointCloud()        \n",
    "        maskpcl.points = o3d.utility.Vector3dVector(xyz)    \n",
    "        maskpcl.colors = o3d.utility.Vector3dVector(mask)         \n",
    "        maskpcds.append(maskpcl)    \n",
    "        \n",
    "    \n",
    "    return  pcds, maskpcds\n",
    "\n",
    "def pairwise_registration(source, target):    \n",
    "    voxel_sizes = o3d.utility.DoubleVector([0.1, 0.05, 0.025])\n",
    "\n",
    "    # List of Convergence-Criteria for Multi-Scale ICP:\n",
    "    criteria_list = [\n",
    "        o3d.t.pipelines.registration.ICPConvergenceCriteria(relative_fitness=0.0001, relative_rmse=0.0001, max_iteration=20),\n",
    "        o3d.t.pipelines.registration.ICPConvergenceCriteria(0.00001, 0.00001, 15),\n",
    "        o3d.t.pipelines.registration.ICPConvergenceCriteria(0.000001, 0.000001, 10)\n",
    "    ]\n",
    "\n",
    "    # `max_correspondence_distances` for Multi-Scale ICP (o3d.utility.DoubleVector):\n",
    "    max_correspondence_distances = o3d.utility.DoubleVector([0.3, 0.14, 0.07])\n",
    "\n",
    "    # Initial alignment or source to target transform.\n",
    "    init_source_to_target = o3d.core.Tensor.eye(4, o3d.core.Dtype.Float32)\n",
    "\n",
    "    mu, sigma = 0, .1  # mean and standard deviation\n",
    "    # Select the `Estimation Method`, and `Robust Kernel` (for outlier-rejection).\n",
    "    #estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    #estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPlane(o3d.t.pipelines.registration.robust_kernel.RobustKernel(\n",
    "    #        o3d.t.pipelines.registration.robust_kernel.RobustKernelMethod.TukeyLoss, sigma))\n",
    "    #estimation = o3d.t.pipelines.registration.TransformationEstimationForGeneralizedICP()\n",
    "    \n",
    "    estimation = o3d.t.pipelines.registration.TransformationEstimationForColoredICP()#o3d.t.pipelines.registration.robust_kernel.RobustKernel(\n",
    "    #        o3d.t.pipelines.registration.robust_kernel.RobustKernelMethod.TukeyLoss, sigma))\n",
    "\n",
    "    #Save iteration wise `fitness`, `inlier_rmse`, etc. to analyse and tune result.\n",
    "    save_loss_log = True\n",
    "    \n",
    "    s = time.time()\n",
    "    #source_cuda = o3d.t.geometry.PointCloud().from_legacy(source).cuda(0)\n",
    "    #target_cuda = o3d.t.geometry.PointCloud().from_legacy(target).cuda(0)\n",
    "    \n",
    "    #source_cuda.estimate_normals(max_nn=30, radius=.035)\n",
    "    #target_cuda.estimate_normals(max_nn=30, radius=.035)\n",
    "    #master.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "    #source_cuda.estimate_normals()\n",
    "    #target_cuda.estimate_normals()\n",
    "    #print(source_cuda)\n",
    "\n",
    "    registration_ms_icp = o3d.t.pipelines.registration.multi_scale_icp(source, target,\n",
    "                                           voxel_sizes, criteria_list,\n",
    "                                           max_correspondence_distances, estimation_method = estimation)#,\n",
    "                                           #result_ransac.transformation, estimation,\n",
    "                                           #save_loss_log)\n",
    "    transformation_icp = registration_ms_icp.transformation\n",
    "    information_icp = o3d.t.pipelines.registration.get_information_matrix(source, target, max_correspondence_distances[2], registration_ms_icp.transformation)\n",
    "    \n",
    "    ms_icp_time = time.time() - s\n",
    "    print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "    print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "    print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "    #master = target_cuda + master.transform(registration_ms_icp.transformation)\n",
    "    #master = master.voxel_down_sample(voxel_size=.025)\n",
    "    #master.estimate_normals()\n",
    "    \n",
    "    \n",
    "    #print(\"Apply point-to-plane ICP\")\n",
    "    # icp_coarse = o3d.pipelines.registration.registration_icp(\n",
    "    #     source, target, max_correspondence_distance_coarse, np.identity(4),\n",
    "    #     o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    # icp_fine = o3d.pipelines.registration.registration_icp(\n",
    "    #     source, target, max_correspondence_distance_fine,\n",
    "    #     icp_coarse.transformation,\n",
    "    #     o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    # transformation_icp = icp_fine.transformation\n",
    "    # information_icp = o3d.pipelines.registration.get_information_matrix_from_point_clouds(\n",
    "    #     source, target, max_correspondence_distance_fine,\n",
    "    #     icp_fine.transformation)\n",
    "    return transformation_icp, information_icp\n",
    "\n",
    "\n",
    "def full_registration(pcds):\n",
    "    pose_graph = o3d.pipelines.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "    \n",
    "    fpcds = []\n",
    "    for i in range(n_pcds):\n",
    "        pc = o3d.t.geometry.PointCloud().from_legacy(pcds[i]).cuda(0)        \n",
    "        pc.estimate_normals(max_nn=30, radius=.035)\n",
    "        fpcds.append(pc)\n",
    "    \n",
    "    for source_id in range(n_pcds):\n",
    "        for target_id in range(source_id + 1, n_pcds):\n",
    "            transformation_icp, information_icp = pairwise_registration(fpcds[source_id], fpcds[target_id])\n",
    "            #print(\"Build o3d.pipelines.registration.PoseGraph\")\n",
    "            if target_id == source_id + 1:  # odometry case\n",
    "                odometry = np.dot(transformation_icp.numpy(), odometry)\n",
    "                pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(np.linalg.inv(odometry)))\n",
    "                pose_graph.edges.append(o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp.numpy(),\n",
    "                                                             information_icp.numpy(),\n",
    "                                                             uncertain=False))\n",
    "            else:  # loop closure case\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp.numpy(),\n",
    "                                                             information_icp.numpy(),\n",
    "                                                             uncertain=True))\n",
    "    return pose_graph\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_rmse(registration_result):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n",
    "    axes.set_title(\"Inlier RMSE vs Iteration\")\n",
    "    axes.plot(registration_result.loss_log[\"index\"].numpy(),\n",
    "              registration_result.loss_log[\"inlier_rmse\"].numpy())\n",
    "\n",
    "\n",
    "def plot_scale_wise_rmse(registration_result):\n",
    "    scales = registration_result.loss_log[\"scale\"].numpy()\n",
    "    iterations = registration_result.loss_log[\"iteration\"].numpy()\n",
    "\n",
    "    num_scales = scales[-1][0] + 1\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=num_scales, figsize=(20, 5))\n",
    "\n",
    "    masks = {}\n",
    "    \n",
    "    for scale in range(0, num_scales):\n",
    "        masks[scale] = registration_result.loss_log[\"scale\"] == scale\n",
    "\n",
    "        rmse = registration_result.loss_log[\"inlier_rmse\"][masks[scale]].numpy()\n",
    "        iteration = registration_result.loss_log[\"iteration\"][\n",
    "            masks[scale]].numpy()\n",
    "\n",
    "        title_prefix = \"Scale Index: \" + str(scale)\n",
    "        axes[scale].set_title(title_prefix + \" Inlier RMSE vs Iteration\")\n",
    "        axes[scale].plot(iteration, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861775e6-4939-4e6f-8a3d-e0300183bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "#frames = loadpickle('bag2')\n",
    "frames = collectframes('bag2', 300)\n",
    "print('DONE Collecting')\n",
    "pcds, maskpcds = load_point_clouds(frames)\n",
    "print(time.time() - s) \n",
    "o3d.visualization.draw_geometries(pcds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5b8b1-b4bf-4421-ac27-9f0dd0ddb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#voxel_sizes = o3d.utility.DoubleVector([0.1, 0.05, 0.025])\n",
    "voxel_sizes = o3d.utility.DoubleVector([0.2, 0.1, 0.05, 0.025])\n",
    "#voxel_sizes = o3d.utility.DoubleVector([0.2, 0.1, 0.05])\n",
    "#voxel_sizes = o3d.utility.DoubleVector([0.1, 0.05, 0.025, 0.012])\n",
    "# List of Convergence-Criteria for Multi-Scale ICP:\n",
    "criteria_list = [\n",
    "    o3d.t.pipelines.registration.ICPConvergenceCriteria(relative_fitness=0.0001, relative_rmse=0.0001, max_iteration=30),\n",
    "    o3d.t.pipelines.registration.ICPConvergenceCriteria(relative_fitness=0.0001, relative_rmse=0.0001, max_iteration=30),\n",
    "    o3d.t.pipelines.registration.ICPConvergenceCriteria(0.00001, 0.00001, 15),\n",
    "    o3d.t.pipelines.registration.ICPConvergenceCriteria(0.000001, 0.000001, 10)\n",
    "    \n",
    "]\n",
    "\n",
    "# `max_correspondence_distances` for Multi-Scale ICP (o3d.utility.DoubleVector):\n",
    "max_correspondence_distances = o3d.utility.DoubleVector([0.6, 0.3, 0.14, 0.07])\n",
    "\n",
    "# Initial alignment or source to target transform.\n",
    "init_source_to_target = o3d.core.Tensor.eye(4, o3d.core.Dtype.Float32)\n",
    "\n",
    "#mu, sigma = 0, 2  # mean and standard deviation\n",
    "# Select the `Estimation Method`, and `Robust Kernel` (for outlier-rejection).\n",
    "#estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "#estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "estimation = o3d.t.pipelines.registration.TransformationEstimationForColoredICP()\n",
    "#estimation = o3d.t.pipelines.registration.TransformationEstimationForColoredICP(o3d.t.pipelines.registration.robust_kernel.RobustKernel(\n",
    "#            o3d.t.pipelines.registration.robust_kernel.RobustKernelMethod.TukeyLoss, sigma))\n",
    "#estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPlane(o3d.t.pipelines.registration.robust_kernel.RobustKernel(\n",
    "#        o3d.t.pipelines.registration.robust_kernel.RobustKernelMethod.TukeyLoss, sigma))\n",
    "#estimation = o3d.t.pipelines.registration.TransformationEstimationPointToPlane(o3d.t.pipelines.registration.robust_kernel.RobustKernel(\n",
    "#        o3d.t.pipelines.registration.robust_kernel.RobustKernelMethod.L2Loss, sigma))\n",
    "\n",
    "# Save iteration wise `fitness`, `inlier_rmse`, etc. to analyse and tune result.\n",
    "#save_loss_log = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ca945-bf86-42bf-a6ab-aa466d3391d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,200): \n",
    "    pcds[i] = pcds[i].voxel_down_sample(voxel_size=0.02)\n",
    "    maskpcds[i] = maskpcds[i].voxel_down_sample(voxel_size=0.02)\n",
    "    pcds[i], o = pcds[i].remove_radius_outlier(15, .05,True)\n",
    "    maskpcds[i], o = maskpcds[i].remove_radius_outlier(15, .05,True)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35de2b5-e064-4aaf-a744-0e52affb67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "outtest = copy.deepcopy(pcds[0])\n",
    "voxel_down_pcd = outtest.voxel_down_sample(voxel_size=0.02)\n",
    "o3d.visualization.draw_geometries([voxel_down_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c3f0a-17b7-45e2-8f02-f03c4d17e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "outtest, ind = voxel_down_pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e7661-4e73-46d1-a042-bdf33431ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outtest, o = outtest.remove_radius_outlier(15, .05,True)\n",
    "#pcds[i], o = pcds[i].remove_radius_outlier(15, .05,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe7a9b-6c2b-4031-b95e-058eba2108f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([outtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8b8df-2d01-4ad4-9efe-f5bde6b7c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "tottime = time.time()\n",
    "voxel_size=0.1\n",
    "master = o3d.t.geometry.PointCloud().from_legacy(pcds[0])\n",
    "hotpink =  o3d.t.geometry.PointCloud().from_legacy(maskpcds[0])\n",
    "#master = master.cuda(0)\n",
    "#master = master.voxel_down_sample(voxel_size=0.025)\n",
    "master.estimate_normals(max_nn=30, radius=.05)\n",
    "\n",
    "#cl, ind = master.remove_statistical_outlier(nb_neighbors=20, std_ratio=1.0)\n",
    "#master = cl\n",
    "#cl, ind = master.remove_radius_outlier(nb_points=10, radius=0.05)\n",
    "#master = cl\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,40):    \n",
    "    s = time.time()\n",
    "    #source_cuda = master#.cuda(0)\n",
    "    #pcds[i].cuda(0)\n",
    "    # source_down, source_fpfh = preprocess_point_cloud(pcds[i-1], voxel_size)\n",
    "    # target_down, target_fpfh = preprocess_point_cloud(pcds[i], voxel_size)\n",
    "    # start = time.time()        \n",
    "    # result_ransac = execute_fast_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    # print(result_ransac)\n",
    "    # print(\"Global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    source_cuda = o3d.t.geometry.PointCloud().from_legacy(pcds[i-1])\n",
    "    #source_cuda, o = source_cuda.remove_radius_outliers(20, .05)\n",
    "    source_cuda = source_cuda.cuda(0)    \n",
    "    \n",
    "    \n",
    "    target_cuda = o3d.t.geometry.PointCloud().from_legacy(pcds[i])\n",
    "    #target_cuda, o = target_cuda.remove_radius_outliers(20, .05)\n",
    "    target_cuda = target_cuda.cuda(0)\n",
    "    #target_cuda = target_cuda.voxel_down_sample(voxel_size=0.025)\n",
    "    \n",
    "    #target_cuda.estimate_normals(max_nn=30, radius=.035)\n",
    "    #cl, ind = target_cuda.remove_statistical_outlier(nb_neighbors=20, std_ratio=1.0)\n",
    "    #target_cuda = cl\n",
    "    #cl, ind= target_cuda.remove_radius_outlier(nb_points=10, radius=0.05)\n",
    "    #target_cuda = cl\n",
    "    #source_cuda.estimate_normals()\n",
    "    target_cuda.estimate_normals(max_nn=30, radius=.05)\n",
    "    #print(master)\n",
    "    \n",
    "    #master = o3d.t.geometry.PointCloud().from_legacy(master)   \n",
    "    \n",
    "    \n",
    "    registration_ms_icp = o3d.t.pipelines.registration.multi_scale_icp(source_cuda, target_cuda,\n",
    "                                           voxel_sizes, criteria_list,\n",
    "                                           max_correspondence_distances, estimation_method = estimation)#, init_source_to_target = result_ransac.transformation)#, save_loss_log=False)#,\n",
    "                                           #result_ransac.transformation, estimation,\n",
    "                                           #save_loss_log)\n",
    "\n",
    "    source_cuda = source_cuda.cpu()\n",
    "    target_cuda = target_cuda.cpu()\n",
    "    ms_icp_time = time.time() - s\n",
    "    print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "    print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "    print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "    #plot_rmse(registration_ms_icp)\n",
    "    \n",
    "    #pcds[i-1] = pcds[i-1].transform(registration_ms_icp.transformation.numpy())\n",
    "    master = master.transform(registration_ms_icp.transformation) + target_cuda \n",
    "    hotpink = hotpink.transform(registration_ms_icp.transformation) + o3d.t.geometry.PointCloud().from_legacy(maskpcds[i]) \n",
    "    \n",
    "    #target_cuda.cpu(0)\n",
    "    #print(master.point['positions'].shape[0])\n",
    "    #if master.point['positions'].shape[0] >  400000:\n",
    "    #    master = master.voxel_down_sample(voxel_size=.025)\n",
    "    #master.estimate_normals(max_nn=30, radius=.035)\n",
    "    #master = master.to_legacy()\n",
    "    \n",
    "print(time.time() - tottime)\n",
    "#master = master.voxel_down_sample(voxel_size=.02)\n",
    "master = master.to_legacy()\n",
    "hotpink = hotpink.to_legacy()\n",
    "#master, ind = master.remove_radius_outlier(nb_points=20, radius=0.05)\n",
    "o3d.visualization.draw_geometries([hotpink])\n",
    "o3d.visualization.draw_geometries([master])\n",
    "#draw_registration_result(source_cuda.cpu(), target_cuda.cpu(), registration_ms_icp.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1536cf3-4707-4d25-8398-8b630c57c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([master])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a2280-6e4a-401d-b637-a5e8027d520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([hotpink2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ff6c7-1b19-470e-a7e9-454fcdb9c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([master])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5beb6e5-9faa-400a-918c-03d886b90174",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = copy.deepcopy(hotpink)\n",
    "pcd = pcd.voxel_down_sample(voxel_size=0.025)\n",
    "plane_model, inliers = pcd.segment_plane(distance_threshold=0.2,\n",
    "                                         ransac_n=3,\n",
    "                                         num_iterations=1000)\n",
    "[a, b, c, d] = plane_model\n",
    "print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "\n",
    "inlier_cloud = pcd.select_by_index(inliers)\n",
    "inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "o3d.visualization.draw_geometries([outlier_cloud])\n",
    "#o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223f489-6630-403b-b665-d62380b86562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plane_model, inliers = outlier_cloud.segment_plane(distance_threshold=0.08,\n",
    "                                         ransac_n=3,\n",
    "                                         num_iterations=1000)\n",
    "[a, b, c, d] = plane_model\n",
    "print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "\n",
    "inlier_cloud = outlier_cloud.select_by_index(inliers)\n",
    "inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "outlier_cloud = outlier_cloud.select_by_index(inliers, invert=True)\n",
    "o3d.visualization.draw_geometries([outlier_cloud])\n",
    "#o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ac9c7-6c4b-4e1a-96ff-fd79a4a4d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pinkcolors = np.asarray(outlier_cloud.colors)\n",
    "pinkpoints = np.asarray(outlier_cloud.points)\n",
    "pcolors = pinkcolors * 255\n",
    "pink = np.where(pcolors[:,0] == 255)\n",
    "hotpoints = pinkpoints[pink]\n",
    "hotcolors = pinkcolors[pink]\n",
    "hotpink2 = o3d.geometry.PointCloud()        \n",
    "hotpink2.points = o3d.utility.Vector3dVector(hotpoints)    \n",
    "hotpink2.colors = o3d.utility.Vector3dVector(hotcolors)    \n",
    "o3d.visualization.draw_geometries([hotpink2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c983f14-480b-4772-a639-dab885ac3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpink2, o = hotpink2.remove_radius_outlier(15, .05,True)\n",
    "o3d.visualization.draw_geometries([hotpink2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8e114-33b2-4778-a7b8-c170c80350f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pcd = outlier_cloud.voxel_down_sample(voxel_size=0.025)\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    labels = np.array(pcd.cluster_dbscan(eps=0.1, min_points=30, print_progress=True))\n",
    "\n",
    "max_label = labels.max()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "colors[labels < 0] = 0\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114351b-f7ed-4146-9536-d17b85033f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Full registration ...\")\n",
    "# max_correspondence_distance_coarse = voxel_size * 15\n",
    "# max_correspondence_distance_fine = voxel_size * 1.5\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Info) as cm:\n",
    "    pose_graph = full_registration(pcds[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87296a-1db9-43dd-8ff5-48bfec92ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimizing PoseGraph ...\")\n",
    "option = o3d.pipelines.registration.GlobalOptimizationOption(\n",
    "    max_correspondence_distance=max_correspondence_distances[2],\n",
    "    edge_prune_threshold=0.25,\n",
    "    reference_node=0)\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    o3d.pipelines.registration.global_optimization(\n",
    "        pose_graph,\n",
    "        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "        o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n",
    "        option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179e972-dfc5-4e97-b29b-d9eb39832a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transform points and display\")\n",
    "legacy = []\n",
    "for point_id in range(len(pcds[:50])):\n",
    "    print(pose_graph.nodes[point_id].pose)\n",
    "    p = copy.deepcopy(pcds[point_id])\n",
    "    p.transform(pose_graph.nodes[point_id].pose)\n",
    "    legacy.append(p)\n",
    "o3d.visualization.draw_geometries(legacy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d771d-842f-41c3-8f20-d99ed4a75502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pcds = load_point_clouds(voxel_size)\n",
    "pcd_combined = o3d.geometry.PointCloud()\n",
    "for point_id in range(len(pcds)):\n",
    "    pcds[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "    pcd_combined += pcds[point_id]\n",
    "pcd_combined_down = pcd_combined.voxel_down_sample(voxel_size=voxel_size*.5)\n",
    "#o3d.io.write_point_cloud(\"multiway_registration.pcd\", pcd_combined_down)\n",
    "o3d.visualization.draw_geometries([pcd_combined_down],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53acff-2187-4eb1-a443-ea9464a8dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = None\n",
    "for _ in range(5):\n",
    "    voxel_size = 0.05\n",
    "    pcds_down, pcds = load_point_clouds(voxel_size)\n",
    "    #o3d.visualization.draw_geometries(pcds_down)\n",
    "    print(\"Full registration ...\")\n",
    "  \n",
    "    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Info) as cm:\n",
    "        pose_graph = full_registration(pcds_down,\n",
    "                                   max_correspondence_distance_coarse,\n",
    "                                   max_correspondence_distance_fine)\n",
    "    \n",
    "    print(\"Transform points and display\")\n",
    "    for point_id in range(len(pcds_down)):\n",
    "        #print(pose_graph.nodes[point_id].pose)\n",
    "        pcds_down[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "    #o3d.visualization.draw_geometries(pcds_down)\n",
    "    \n",
    "    \n",
    "    pcd_combined = o3d.geometry.PointCloud()\n",
    "    for point_id in range(len(pcds)):\n",
    "        pcds[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "        pcd_combined += pcds[point_id]\n",
    "    pcd_combined_down = pcd_combined.voxel_down_sample(voxel_size=voxel_size*.5)\n",
    "    \n",
    "    if master == None:\n",
    "        master = pcd_combined_down\n",
    "    else:\n",
    "        \n",
    "        source_down, source_fpfh = preprocess_point_cloud(master, voxel_size)\n",
    "        target_down, target_fpfh = preprocess_point_cloud(pcd_combined_down, voxel_size)\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        result_ransac = execute_fast_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    \n",
    "        print(result_ransac)\n",
    "        print(\"Global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "    \n",
    "    \n",
    "    \n",
    "        master.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "        pcd_combined_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    \n",
    "        start = time.time()\n",
    "        result_icp = refine_registration(master, pcd_combined_down, source_fpfh, target_fpfh, voxel_size)\n",
    "        \n",
    "    \n",
    "        master = master.transform(result_icp.transformation)\n",
    "        master = master + pcd_combined_down\n",
    "        master = master.voxel_down_sample(voxel_size=voxel_size*.5)\n",
    "        print(result_icp)\n",
    "        print(\"Point to Plane registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "        # radius_normal = voxel_size * 2\n",
    "        # pcd_combined_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "        # transformation_icp, information_icp = pairwise_registration(master, pcd_combined_down)\n",
    "        # pcd_combined_down = pcd_combined_down.transform(transformation_icp)\n",
    "        # master = master + pcd_combined_down\n",
    "    \n",
    "    \n",
    "    \n",
    "o3d.visualization.draw_geometries([master])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2e680-4387-4e31-b9ad-1e9edf8e6acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad154e-7e8d-403c-bc37-cb48b7f5ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input point-clouds\n",
    "demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "source = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "target = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[1])\n",
    "\n",
    "source_cuda = source.cuda(0)\n",
    "target_cuda = target.cuda(0)\n",
    "s = time.time()\n",
    "\n",
    "registration_ms_icp = treg.multi_scale_icp(source_cuda, target_cuda,\n",
    "                                           voxel_sizes, criteria_list,\n",
    "                                           max_correspondence_distances,\n",
    "                                           init_source_to_target, estimation,\n",
    "                                           save_loss_log)\n",
    "\n",
    "ms_icp_time = time.time() - s\n",
    "print(\"Time taken by Multi-Scale ICP: \", ms_icp_time)\n",
    "print(\"Inlier Fitness: \", registration_ms_icp.fitness)\n",
    "print(\"Inlier RMSE: \", registration_ms_icp.inlier_rmse)\n",
    "\n",
    "draw_registration_result(source.cpu(), target.cpu(),\n",
    "                         registration_ms_icp.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83f30b-594a-4408-b22e-41c708159762",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([master])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e73c7-0bd8-4e4f-83a3-8e6982e6d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pcd = pcd_combined_down\n",
    "\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    labels = np.array(\n",
    "        pcd.cluster_dbscan(eps=0.08, min_points=50, print_progress=True))\n",
    "\n",
    "max_label = labels.max()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "colors[labels < 0] = 0\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "o3d.visualization.draw_geometries([pcd],\n",
    "                                  zoom=0.455,\n",
    "                                  front=[-0.4999, -0.1659, -0.8499],\n",
    "                                  lookat=[2.1813, 2.0619, 2.0999],\n",
    "                                  up=[0.1204, -0.9852, 0.1215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159be34d-0d80-4ac9-bdc1-36cb5f52cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result_original_color(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target],\n",
    "                                      zoom=0.5,\n",
    "                                      front=[-0.2458, -0.8088, 0.5342],\n",
    "                                      lookat=[1.7745, 2.2305, 0.9787],\n",
    "                                      up=[0.3109, -0.5878, -0.7468])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625fc821-40a5-4ebb-bbdf-38926814e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1. Load two point clouds and show initial pose\")\n",
    "demo_colored_icp_pcds = o3d.data.DemoColoredICPPointClouds()\n",
    "source = o3d.io.read_point_cloud(demo_colored_icp_pcds.paths[0])\n",
    "target = o3d.io.read_point_cloud(demo_colored_icp_pcds.paths[1])\n",
    "\n",
    "# draw initial alignment\n",
    "#current_transformation = np.identity(4)\n",
    "#draw_registration_result_original_color(source, target, current_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898f2bc-5d61-4e6b-9854-6636b64fe2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source.points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3aa68-b360-4eb3-828d-bffbd6e1cab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "o3d",
   "language": "python",
   "name": "o3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
